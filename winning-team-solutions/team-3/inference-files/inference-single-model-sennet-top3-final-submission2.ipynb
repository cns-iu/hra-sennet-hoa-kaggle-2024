{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Create a new conda environment with python=3.10 and install the required packages."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# !pip download segmentation_models_pytorch -d segmentation-models-pytorch"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# !python -m pip install --no-index --find-links=./segmentation-models-pytorch/ segmentation_models_pytorch"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# # Install cv2 module for image processing\n","# !pip install -q -U opencv-python\n","# # Install matplotlib for plotting\n","# !pip install -q -U matplotlib\n","# # Install albumenatations for image augmentations\n","# !pip install -q -U albumentations\n","# # Install pandas for data manipulation\n","# !pip install -q -U pandas\n","# # Install numba for fast computation\n","# !pip install -q -U numba"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["model_ls = [\n","    {\n","        \"model_name\":\"Unet\", \n","        \"backbone\":\"tu-maxvit_large_tf_512\",\n","        \"weight\": './trained-model-weights/sennet0205/allpse_maxViTlarge/allpse_maxViTlarge/valonK-1_last.pt',\n","        \"image_size\":512, \n","        \"stride\":512, \n","        \"batch_size\":4,\n","        \"in_chans\": 1,\n","        \"have_large_res\":False,\n","        \"tta_ls\":[[2], [2,3]],\n","    }\n","]\n","\n","refine_model_ls = [\n","#     {\n","#         \"model_name\":\"Unet\", \n","#         \"backbone\":\"tu-tf_efficientnetv2_s\",\n","#         \"weight\":'/kaggle/input/model4pseudolabel/NonemptyMask_UNeteffv2s_900onwards_Scale55-105_noval/NonemptyMask_UNeteffv2s_900onwards_Scale55-105_noval/valonK-1_last.pt', \n","#         \"image_size\":512, \n","#         \"stride\":512, \n","#         \"batch_size\":32,\n","#         \"in_chans\": 1\n","#     },\n","#     {\n","#         \"model_name\":\"Unet\", \n","#         \"backbone\":\"tu-tf_efficientnetv2_l\",\n","#         \"weight\":'/kaggle/input/sennet0131/NonemptyMask_UNeteffv2l_900onwards_Scale55-105_valtrans/NonemptyMask_UNeteffv2l_900onwards_Scale55-105_valtrans/valonK3_best_dice.pt', \n","#         \"image_size\":512, \n","#         \"stride\":512, \n","#         \"batch_size\":8,\n","#         \"in_chans\": 1\n","#     },\n","]"]},{"cell_type":"code","execution_count":6,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-02-06T06:33:23.002829Z","iopub.status.busy":"2024-02-06T06:33:23.002515Z","iopub.status.idle":"2024-02-06T06:33:51.330012Z","shell.execute_reply":"2024-02-06T06:33:51.329199Z","shell.execute_reply.started":"2024-02-06T06:33:23.002799Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/u/yashjain/anaconda3/envs/k4-team-3-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["# !python -m pip install --no-index --find-links=/kaggle/input/pip-download-for-segmentation-models-pytorch segmentation-models-pytorch\n","import torch as tc \n","import torch.nn as nn  \n","import numpy as np\n","from tqdm import tqdm\n","import os,sys,cv2\n","from torch.cuda.amp import autocast\n","import matplotlib.pyplot as plt\n","import albumentations as A\n","import segmentation_models_pytorch as smp\n","from albumentations.pytorch import ToTensorV2\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.parallel import DataParallel\n","from glob import glob\n","import random\n","import torch\n","import pandas as pd\n","import argparse  \n","import sys\n","from PIL import Image\n","import sys\n","\n","sys.path.append(f'{os.getcwd()}/sennet-metrics')\n","sys.path.append(f'{os.getcwd()}/sennet-metrics/src')\n","\n","from sennet_metrices import *\n","import gc\n","import time\n","\n","def rle_encode(mask):\n","    pixel = mask.flatten()\n","    pixel = np.concatenate([[0], pixel, [0]])\n","    run = np.where(pixel[1:] != pixel[:-1])[0] + 1\n","    run[1::2] -= run[::2]\n","    rle = ' '.join(str(r) for r in run)\n","    if rle == '':\n","        rle = '1 0'\n","    return rle\n","\n","def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","seed_everything(42)\n","CHOPPING_PER =1e-3"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T06:33:51.331649Z","iopub.status.busy":"2024-02-06T06:33:51.331188Z","iopub.status.idle":"2024-02-06T06:33:51.337307Z","shell.execute_reply":"2024-02-06T06:33:51.336481Z","shell.execute_reply.started":"2024-02-06T06:33:51.331619Z"},"trusted":true},"outputs":[],"source":["valid_aug_list = [\n","    ToTensorV2(),\n","]\n","valid_aug = A.Compose(valid_aug_list)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T06:33:51.340649Z","iopub.status.busy":"2024-02-06T06:33:51.340039Z","iopub.status.idle":"2024-02-06T06:33:51.354243Z","shell.execute_reply":"2024-02-06T06:33:51.353492Z","shell.execute_reply.started":"2024-02-06T06:33:51.340616Z"},"trusted":true},"outputs":[],"source":["class CustomModel(nn.Module):\n","    def __init__(self, model_name, backbone, in_chans=1, target_size=1, weight=None):\n","        super().__init__()\n","        if model_name == 'Unet':\n","            self.model = smp.Unet(\n","                encoder_name=backbone, \n","                encoder_weights=weight,\n","                in_channels=in_chans,\n","                classes=target_size,\n","                activation=None,\n","            )\n","        elif model_name == 'UnetPlusPlus':\n","            self.model = smp.UnetPlusPlus(\n","                encoder_name=backbone, \n","                encoder_weights=weight,\n","                in_channels=in_chans,\n","                classes=target_size,\n","                activation=None,\n","            )            \n","\n","    def forward(self, image):\n","        output = self.model(image)\n","        return output[:,0]\n","\n","\n","def build_model(model_name, backbone, in_chans=1):\n","    print('model_name', model_name)\n","    print('backbone', backbone)\n","    model = CustomModel(model_name, backbone, in_chans=in_chans)\n","\n","    return model.cuda()"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T06:33:51.355399Z","iopub.status.busy":"2024-02-06T06:33:51.355137Z","iopub.status.idle":"2024-02-06T06:33:51.371604Z","shell.execute_reply":"2024-02-06T06:33:51.370824Z","shell.execute_reply.started":"2024-02-06T06:33:51.355372Z"},"trusted":true},"outputs":[],"source":["def normalize_img(in_img, eps=1e-9):\n","    min_ = in_img.min()\n","    max_ = in_img.max()\n","    return (255 * (in_img - min_) / (max_ - min_ + eps)).astype(np.uint8)\n","\n","\n","def add_noise(x:tc.Tensor,max_randn_rate=0.1,randn_rate=None,x_already_normed=False):\n","    \"\"\"input.shape=(batch,f1,f2,...) output's var will be normalizate  \"\"\"\n","    ndim=x.ndim-1\n","    if x_already_normed:\n","        x_std=tc.ones([x.shape[0]]+[1]*ndim,device=x.device,dtype=x.dtype)\n","        x_mean=tc.zeros([x.shape[0]]+[1]*ndim,device=x.device,dtype=x.dtype)\n","    else: \n","        dim=list(range(1,x.ndim))\n","        x_std=x.std(dim=dim,keepdim=True)\n","        x_mean=x.mean(dim=dim,keepdim=True)\n","    if randn_rate is None:\n","        randn_rate=max_randn_rate*np.random.rand()*tc.rand(x_mean.shape,device=x.device,dtype=x.dtype)\n","    cache=(x_std**2+(x_std*randn_rate)**2)**0.5\n","    return (x-x_mean+tc.randn(size=x.shape,device=x.device,dtype=x.dtype)*randn_rate*x_std)/(cache+1e-7)\n","\n","def filter_noise(x):\n","    TH=x.reshape(-1)\n","    index = -int(len(TH) * CHOPPING_PER)\n","    TH:int = np.partition(TH, index)[index]\n","    x[x>TH]=int(TH)\n","    ########################################################################\n","    TH=x.reshape(-1)\n","    index = -int(len(TH) * CHOPPING_PER)\n","    TH:int = np.partition(TH, -index)[-index]\n","    x[x<TH]=int(TH)\n","    return x"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T06:33:51.373191Z","iopub.status.busy":"2024-02-06T06:33:51.372932Z","iopub.status.idle":"2024-02-06T06:33:51.580892Z","shell.execute_reply":"2024-02-06T06:33:51.579733Z","shell.execute_reply.started":"2024-02-06T06:33:51.37317Z"},"trusted":true},"outputs":[],"source":["def get_indexes_along_axis0(num_slice, height, width, image_size, stride, slice_offset, nonempty_slices):\n","    indexes = []\n","    cur_h, cur_w = 0, 0\n","    flag = 0\n","    while(cur_h < height or cur_w < width):\n","        if (cur_h + image_size <= height) and (cur_w + image_size <= width):\n","            indexes.append((cur_h, cur_w))\n","            cur_w += stride\n","        elif (cur_h + image_size <= height) and (cur_w + image_size > width):\n","            indexes.append((cur_h, width - image_size)) \n","            cur_h += stride\n","            cur_w = 0\n","\n","        if (cur_h + image_size > height):\n","            if flag == 0:\n","                cur_h = height - image_size \n","                flag = 1\n","            else:\n","                break\n","\n","    indexes_3d = []\n","    if nonempty_slices is None: slice_ls = range(slice_offset, num_slice-slice_offset)\n","    else: slice_ls = nonempty_slices\n","    for slice_idx in slice_ls:\n","        for h, w in indexes:\n","            indexes_3d.append((slice_idx, h, w))\n","    return indexes_3d\n","\n","def norm_with_clip(x:torch.Tensor,smooth=1e-5):\n","    dim=list(range(1,x.ndim))\n","    mean=x.mean(dim=dim,keepdim=True)\n","    std=x.std(dim=dim,keepdim=True)\n","    x=(x-mean)/(std+smooth)\n","    x[x>5]=(x[x>5]-5)*1e-3 +5\n","    x[x<-3]=(x[x<-3]+3)*1e-3-3\n","    return x\n","\n","def min_max_normalization(x:tc.Tensor)->tc.Tensor:\n","    \"\"\"input.shape=(batch,f1,...)\"\"\"\n","    shape=x.shape\n","    if x.ndim>2:\n","        x=x.reshape(x.shape[0],-1)\n","    \n","    min_=x.min(dim=-1,keepdim=True)[0]\n","    max_=x.max(dim=-1,keepdim=True)[0]\n","    if min_.mean()==0 and max_.mean()==1:\n","        return x.reshape(shape)\n","    \n","    x=(x-min_)/(max_-min_+1e-9)\n","    return x.reshape(shape)\n","\n","def pad_hw(images, pad_h, pad_w):\n","    pad_width = [(0, 0),  \n","                 (pad_h, pad_h),  \n","                 (pad_w, pad_w)]  \n","    images = np.pad(images, pad_width=pad_width, mode='constant')\n","    return images\n","\n","class Dataset3D(Dataset):\n","    def __init__(self, image_list, label_list=None, trans_axis=0,image_size=512, in_chans=1,stride=512,aug=False, pad_h=0, pad_w=0, nonempty_slices=None):\n","        super(Dataset,self).__init__()\n","\n","        self.image_size=image_size\n","        self.in_chans=in_chans\n","        assert self.in_chans % 2 == 1\n","        self.slice_offset = (self.in_chans - 1)//2\n","        images = [cv2.imread(x,cv2.IMREAD_GRAYSCALE)[np.newaxis, :, :] for x in image_list]\n","        images = np.concatenate(images, axis=0)## N, H, W\n","\n","        self.label_list = label_list\n","        images = torch.tensor(filter_noise(images))\n","        images = (min_max_normalization(images.to(tc.float16)[None])[0]*255).to(tc.uint8).numpy()\n","        if label_list is not None:\n","            labels = [cv2.imread(x,cv2.IMREAD_GRAYSCALE)[np.newaxis, :, :] for x in label_list]\n","            labels = np.concatenate(labels, axis=0).astype(np.uint8)\n","        else:\n","            labels = None      \n","\n","        if trans_axis == 1:\n","            images = np.transpose(images, (1,2,0))\n","            if label_list is not None:\n","                labels = np.transpose(labels, (1,2,0))\n","        if trans_axis == 2:\n","            images = np.transpose(images, (2,0,1))\n","            if label_list is not None:\n","                labels = np.transpose(labels, (2,0,1))\n","        self.trans_axis = trans_axis       \n","        images = pad_hw(images, pad_h, pad_w)\n","        \n","        self.images = [images]\n","        self.labels = [labels]\n","        num_slice, height, width = images.shape\n","        slide_image_size = min(image_size, height-1, width-1)\n","        slide_stride = min(stride, height-1, width-1)\n","        self.coors = get_indexes_along_axis0(num_slice, height, width, slide_image_size, slide_stride, self.slice_offset, nonempty_slices)\n","        self.idx_3d = [0] * len(self.coors)\n","        self.transform=valid_aug\n","\n","    def __len__(self):\n","        return len(self.coors)\n","\n","    def __getitem__(self,index):\n","        n, h, w = self.coors[index]\n","        idx_3d = self.idx_3d[index]\n","        if self.slice_offset == 0:\n","            image = self.images[idx_3d][n, h:h+self.image_size, w:w+self.image_size] # (1, H, W)\n","        else:\n","            image = self.images[idx_3d][n-self.slice_offset:n+self.slice_offset+1, h:h+self.image_size, w:w+self.image_size] # (3(5), H, W)\n","            image = np.transpose(image, (1, 2, 0))            \n","        data = self.transform(image=image)\n","        return data['image'], idx_3d, n, h, w\n","    \n","    def get_labels(self):\n","        return self.labels\n","    \n","\n","def permute_axis(pred, trans_axis=0, direction=0):\n","    \"\"\"\n","    direction: \n","    0: from original shape to transposed shape\n","    1: from transposed shape to original shape\n","    \"\"\"\n","    if trans_axis == 0: \n","        return pred  ## N, H, W\n","    elif trans_axis == 1:\n","        if direction == 0:\n","            pred = pred.permute(1, 2, 0) ## H, W, N\n","        else:\n","            pred = pred.permute(2, 0, 1)  ## N, H, W\n","    elif trans_axis == 2:\n","        if direction == 0:\n","            pred = pred.permute(2, 0, 1) ## W, N, H\n","        else:\n","            pred = pred.permute(1, 2, 0) ## N, H, W\n","    return pred  ## N, H, W\n","\n","def get_nhw(trans_axis, NUM_SLICES, HEIGHT, WIDTH):\n","    if trans_axis == 0:\n","        num_slices, height, width = NUM_SLICES, HEIGHT, WIDTH\n","    elif trans_axis == 1:\n","        num_slices, height, width = HEIGHT, WIDTH, NUM_SLICES\n","    elif trans_axis == 2:\n","        num_slices, height, width = WIDTH, NUM_SLICES, HEIGHT\n","    return num_slices, height, width\n","\n","def get_pad_hw(height, width, image_size, edge_size=16):\n","    if height <= image_size:\n","        pad_h = (image_size - height) // 2 + edge_size\n","    else:\n","        pad_h = 0\n","    if width <= image_size:\n","        pad_w = (image_size - width) // 2 + edge_size\n","    else:\n","        pad_w = 0\n","    return pad_h, pad_w\n","\n","def perd_add2map(preds, preds_cnt, n, h, w, height, width, pad_h, pad_w, image_size, pred, sample_idx):\n","    ### w=0, 4 是pad后在整个slice上的坐标\n","    ### \n","    w_start = max(w-pad_w, 0)\n","    w_end = min(width, w_start+image_size)\n","    h_start = max(h-pad_h, 0)\n","    h_end = min(height, h_start+image_size)\n","    \n","    \n","    if pad_h != 0:\n","        h_pred_start = pad_h - h\n","        h_pred_end = h_pred_start + h_end - h_start\n","    else:\n","        h_pred_start, h_pred_end = 0, image_size\n","    if pad_w != 0:\n","        w_pred_start = pad_w - w\n","        w_pred_end = w_pred_start + w_end - w_start\n","    else:\n","        w_pred_start, w_pred_end = 0, image_size\n","\n","    preds[n, h_start:h_end, w_start:w_end] += pred[sample_idx][h_pred_start:h_pred_end, w_pred_start:w_pred_end]\n","    preds_cnt[n, h_start:h_end, w_start:w_end] += 1\n","    \n","    return preds, preds_cnt\n","\n","\n","def search_thr(preds, labels, image_ids, width, height, min_thr=0.01, max_thr=0.5, interval=0.01):\n","    thr_list = np.arange(min_thr, max_thr, interval)\n","    thr_list = [round(x, 3) for x in thr_list]\n","    best_dice, best_thr = 0, 0\n","    for thr in tqdm(thr_list, total=len(thr_list)):\n","        ## -------------- 1. Use the thre to get binary pred ---------------\n","        bin_preds = preds > thr\n","        ## -------------- 2. RLE Encode label and preds for each slice---------------\n","        tmp_preds, tmp_labels = [], []\n","        for pred, label in zip(bin_preds, labels):\n","            tmp_preds.append(rle_encode(pred))\n","            tmp_labels.append(rle_encode(label))\n","        ## -------------- 3. Get df---------------\n","        submit = pd.DataFrame({'id': image_ids, 'rle': tmp_preds, 'width':[width]*len(image_ids), 'height': [height]*len(image_ids)})  \n","        label_df = pd.DataFrame({'id': image_ids, 'rle': tmp_labels, 'width':[width]*len(image_ids), 'height': [height]*len(image_ids)})\n","        ## -------------- 4. Surface Dice --------------\n","        surface_dice = compute_surface_dice_score(submit, label_df)\n","        print(f'Surface dice at threshold {thr} is: {surface_dice}')\n","        if surface_dice > best_dice:\n","            best_dice, best_thr = surface_dice, thr\n","\n","    print(f'Best Surface dice at threshold {best_thr} is: {best_dice}')\n","    \n","def filter_empty_slice(preds, threshold=50):\n","    num_slice, h, w = preds.shape\n","    for i in range(num_slice):\n","        if np.sum(preds[i, :, :]) < threshold:\n","            preds[i, :, :] = np.zeros((h, w))\n","    return preds"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T06:33:51.582459Z","iopub.status.busy":"2024-02-06T06:33:51.582113Z","iopub.status.idle":"2024-02-06T06:33:51.657807Z","shell.execute_reply":"2024-02-06T06:33:51.656961Z","shell.execute_reply.started":"2024-02-06T06:33:51.582433Z"},"trusted":true},"outputs":[],"source":["from glob import glob\n","SPLIT = 'test'\n","BASE_DIR = f'/teradata/hra_data/k4_data/competition-data/{SPLIT}'\n","if SPLIT == 'test':\n","    kidney_ls = os.listdir(BASE_DIR)\n","    image_ls, label_ls = [], []\n","    for kidney in kidney_ls:\n","        tmp_img_ls = glob(os.path.join(f'{BASE_DIR}/{kidney}/images', '*.tif'))\n","        tmp_img_ls.sort()\n","        image_ls.append(tmp_img_ls)\n","        label_ls.append(None)\n","else:\n","\n","    kidney = 'kidney_3'\n","    if kidney == 'kidney_2':\n","        tmp_img_ls = glob(os.path.join(f'{BASE_DIR}/{kidney}/images', '*.tif'))\n","        tmp_img_ls.sort()\n","        tmp_img_ls = tmp_img_ls[:600]\n","        tmp_img_ls = glob(os.path.join(f'{BASE_DIR}/{kidney}/images', '*.tif'))\n","        tmp_label_ls = glob(os.path.join(f'{BASE_DIR}/{kidney}/images', '*.tif'))\n","    elif kidney == 'kidney_3':\n","        path1=f\"{BASE_DIR}/kidney_3_sparse\"\n","        path2=f\"{BASE_DIR}/kidney_3_dense\"\n","        tmp_label_ls=glob(f\"{path2}/labels/*\")\n","        tmp_img_ls=[x.replace(\"labels\",\"images\").replace(\"dense\",\"sparse\") for x in tmp_label_ls]\n","        tmp_img_ls.sort()\n","        tmp_label_ls.sort()        \n","#         tmp_img_ls = tmp_img_ls[100:400]\n","#         tmp_label_ls = tmp_label_ls[100:400]\n","        \n","    image_ls = [tmp_img_ls]    \n","    label_ls = [tmp_label_ls]"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T06:33:51.659237Z","iopub.status.busy":"2024-02-06T06:33:51.658973Z","iopub.status.idle":"2024-02-06T06:33:51.681234Z","shell.execute_reply":"2024-02-06T06:33:51.680286Z","shell.execute_reply.started":"2024-02-06T06:33:51.659214Z"},"trusted":true},"outputs":[],"source":["REFINE = False\n","TTA = True\n","# TTA_LS = [[2], [3], [2,3]]\n","TRANS_AXIS = [0,1,2]  #0,1,2\n","if (len(image_ls[0]) == 3): TRANS_AXIS = [0]\n","Stage1_Thres = 0.2\n","Threshold = 0.2# 0.15\n","Discard_thres = 30\n","EMPTY_THRES = 50\n","\n","sample_submission = {'id':[], 'rle':[]}\n","\n","def infer_kidney(NUM_SLICES, HEIGHT, WIDTH,  tmp_image_ls, tmp_label_ls, preds, preds_cnt, nonempty_dict, model_ls=model_ls, trans_axiss=TRANS_AXIS):\n","    for model_idx, model_card in enumerate(model_ls):\n","        TTA_LS = model_card['tta_ls']\n","        for trans_axis in trans_axiss:\n","                    \n","            num_slices, height, width = get_nhw(trans_axis, NUM_SLICES, HEIGHT, WIDTH)   \n","            if  model_card['have_large_res'] and height > model_card[\"large_size\"] and width > model_card[\"large_size\"]:\n","                image_size = model_card[\"large_size\"]\n","                stride = model_card[\"large_stride\"]\n","                weight_path = model_card['largeRes_weight']\n","            else:\n","                image_size = model_card[\"image_size\"]\n","                stride = model_card[\"stride\"]\n","                weight_path = model_card[\"weight\"]\n","            pad_h, pad_w = get_pad_hw(height, width, image_size, edge_size=2)\n","            \n","            val_dataset = Dataset3D(tmp_image_ls, label_list=tmp_label_ls, trans_axis=trans_axis, image_size=image_size, \n","                                    stride=stride, aug=False, pad_h=pad_h, pad_w=pad_w, \n","                                    in_chans=model_card[\"in_chans\"], nonempty_slices=nonempty_dict[trans_axis])\n","            \n","            if SPLIT == 'train':\n","                if trans_axis==0 and model_idx==len(model_ls)-1:\n","                    labels = val_dataset.get_labels()[0]\n","            else:\n","                labels = None\n","                \n","            val_dataset = DataLoader(val_dataset, batch_size=model_card[\"batch_size\"] ,num_workers=4, shuffle=False, drop_last=False)\n","\n","            model=build_model(model_card[\"model_name\"], model_card[\"backbone\"], in_chans=model_card[\"in_chans\"])\n","            model.load_state_dict(tc.load(weight_path,\"cuda:0\"), strict=True)\n","            model.eval()\n","\n","            preds = permute_axis(preds, trans_axis, 0)\n","            preds_cnt = permute_axis(preds_cnt, trans_axis, 0)\n","            for batch_idx, (x,idx_3d, n_bs, h_bs, w_bs) in enumerate(tqdm(val_dataset, total=len(val_dataset))):\n","\n","                x=x.cuda().to(tc.float32)\n","                x=norm_with_clip(x.reshape(-1,*x.shape[2:])).reshape(x.shape)\n","\n","                with autocast():\n","                    with tc.no_grad():\n","                        pred=torch.sigmoid(model(x))\n","                        if TTA and (len(TTA_LS)>0):\n","                            for axis in TTA_LS:  # [2],[3],\n","                                tmp_pred = torch.sigmoid(model(torch.flip(x, dims=axis)))\n","                                axis = [tmp_x-1 for tmp_x in axis]\n","                                tmp_pred = torch.flip(tmp_pred, dims=axis)\n","                                pred += tmp_pred\n","                            pred = pred / (len(TTA_LS)+1)\n","                            \n","                \n","                for sample_idx, (n, h, w) in enumerate(zip(n_bs, h_bs, w_bs)):\n","                    if pad_h == 0 and pad_w == 0:\n","                        preds[n, h:h+image_size, w:w+image_size] += pred[sample_idx]\n","                        preds_cnt[n, h:h+image_size, w:w+image_size] += 1\n","                    else:\n","                        perd_add2map(preds, preds_cnt, n, h, w, height, width, pad_h, pad_w, image_size, pred, sample_idx)\n","            preds = permute_axis(preds, trans_axis, 1)\n","            preds_cnt = permute_axis(preds_cnt, trans_axis, 1)\n","            del model, val_dataset\n","            gc.collect()\n","            torch.cuda.empty_cache()\n","            \n","    return preds, preds_cnt, labels\n","\n","def get_empty_slice_dict_with_seg(preds, preds_cnt, pos_thres=0.2, empty_thres=50):\n","    tmp_preds = torch.div(preds.cpu(), preds_cnt.cpu()).numpy()\n","    tmp_preds = (tmp_preds > pos_thres).astype(np.int8)\n","    nonempty_slices = {0:[], 1:[], 2:[]}\n","    n, h, w = tmp_preds.shape\n","    for i in range(n):\n","        if np.sum(tmp_preds[i, :, :]) > empty_thres:\n","            nonempty_slices[0].append(i)\n","\n","    for i in range(h):\n","        if np.sum(tmp_preds[:, i, :]) > empty_thres:\n","            nonempty_slices[1].append(i)\n","\n","    for i in range(w):\n","        if np.sum(tmp_preds[:, :, i]) > empty_thres:\n","            nonempty_slices[2].append(i)\n","    del tmp_preds\n","    gc.collect()\n","    return nonempty_slices"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T06:33:51.682557Z","iopub.status.busy":"2024-02-06T06:33:51.68227Z","iopub.status.idle":"2024-02-06T07:59:51.376374Z","shell.execute_reply":"2024-02-06T07:59:51.375265Z","shell.execute_reply.started":"2024-02-06T06:33:51.682527Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["model_name Unet\n","backbone tu-maxvit_large_tf_512\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 3036/3036 [16:02<00:00,  3.15it/s]\n"]},{"name":"stdout","output_type":"stream","text":["model_name Unet\n","backbone tu-maxvit_large_tf_512\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2660/2660 [14:01<00:00,  3.16it/s]\n"]},{"name":"stdout","output_type":"stream","text":["model_name Unet\n","backbone tu-maxvit_large_tf_512\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2397/2397 [12:39<00:00,  3.16it/s]\n"]},{"name":"stdout","output_type":"stream","text":["model_name Unet\n","backbone tu-maxvit_large_tf_512\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1128/1128 [05:57<00:00,  3.15it/s]\n"]},{"name":"stdout","output_type":"stream","text":["model_name Unet\n","backbone tu-maxvit_large_tf_512\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1542/1542 [08:08<00:00,  3.16it/s]\n"]},{"name":"stdout","output_type":"stream","text":["model_name Unet\n","backbone tu-maxvit_large_tf_512\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1886/1886 [09:58<00:00,  3.15it/s]\n"]}],"source":["for tmp_image_ls, tmp_label_ls in zip(image_ls, label_ls):\n","    image_ids = [image_path.split('/')[-3] + '_' +image_path.split('/')[-1].split('.')[0] for image_path in tmp_image_ls]\n","    sample_submission['id'].extend(image_ids)\n","    tmp_img = cv2.imread(tmp_image_ls[0],cv2.IMREAD_GRAYSCALE)\n","    HEIGHT, WIDTH = tmp_img.shape\n","    NUM_SLICES = len(image_ids)\n","    preds, preds_cnt = torch.zeros((NUM_SLICES, HEIGHT, WIDTH), dtype=torch.float16).cuda(), torch.zeros((NUM_SLICES, HEIGHT, WIDTH), dtype=torch.int8).cuda()\n","    del tmp_img\n","    gc.collect()\n","    preds, preds_cnt, labels = infer_kidney(NUM_SLICES, HEIGHT, WIDTH,  tmp_image_ls, tmp_label_ls, preds, preds_cnt, \n","                                            nonempty_dict=[None, None, None], model_ls=model_ls, trans_axiss=TRANS_AXIS)\n","    \n","    if REFINE:\n","        nonempty_dict = get_empty_slice_dict_with_seg(preds, preds_cnt, pos_thres=Stage1_Thres, empty_thres=EMPTY_THRES)\n","        preds, preds_cnt, _ = infer_kidney(NUM_SLICES, HEIGHT, WIDTH,  tmp_image_ls, tmp_label_ls, preds, preds_cnt, nonempty_dict=nonempty_dict, model_ls=refine_model_ls, trans_axiss=TRANS_AXIS)\n","    \n","    preds = torch.div(preds.cpu(), preds_cnt.cpu()).numpy()\n","    \n","    if SPLIT == 'test':\n","        ## ------------------ post processing and RLE --------------------\n","        preds = (preds > Threshold).astype(np.int8)\n","#         preds = filter_empty_slice(preds, threshold=Discard_thres)\n","        for pred in preds:\n","            sample_submission['rle'].append(rle_encode(pred))\n","        del preds, preds_cnt\n","        gc.collect()\n","    else:\n","        search_thr(preds, labels, image_ids, WIDTH, HEIGHT, min_thr=0.1, max_thr=0.5, interval=0.01)\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-02-06T07:59:51.380315Z","iopub.status.busy":"2024-02-06T07:59:51.379999Z","iopub.status.idle":"2024-02-06T07:59:51.385241Z","shell.execute_reply":"2024-02-06T07:59:51.384341Z","shell.execute_reply.started":"2024-02-06T07:59:51.380287Z"},"trusted":true},"outputs":[],"source":["if SPLIT == 'test':\n","    sample_submission = pd.DataFrame(sample_submission)\n","    sample_submission.to_csv('submission-validation-single-model.csv', index=False)\n","    sample_submission"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["kidney_5_submit_df shape: (1012, 2)\n","kidney_6_submit_df shape: (501, 2)\n","kidney_5_label_df shape: (1012, 7)\n","kidney_6_label_df shape: (501, 7)\n","Surface dice for public test (kidney_5) set is: 0.8463703393936157\n","Surface dice for private test (kidney_6) set is: 0.7278014421463013\n"]}],"source":["# Compute competition metric.\n","\n","submit_df = pd.read_csv('submission-validation-single-model.csv')\n","label_df = pd.read_csv('/teradata/hra_data/k4_data/competition-data/solution.csv')\n","\n","# Check the id column of the dataframe and separate rows into two dataframes based on if the values contains \"kidney_5\" or \"kidney_6\".\n","kidney_5_submit_df = submit_df[submit_df['id'].str.contains('kidney_5')]\n","kidney_6_submit_df = submit_df[submit_df['id'].str.contains('kidney_6')]\n","print(f'kidney_5_submit_df shape: {kidney_5_submit_df.shape}')\n","print(f'kidney_6_submit_df shape: {kidney_6_submit_df.shape}')\n","\n","kidney_5_label_df = label_df[label_df['id'].str.contains('kidney_5')]\n","kidney_6_label_df = label_df[label_df['id'].str.contains('kidney_6')]\n","print(f'kidney_5_label_df shape: {kidney_5_label_df.shape}')\n","print(f'kidney_6_label_df shape: {kidney_6_label_df.shape}')\n","\n","## -------------- Surface Dice --------------\n","surface_dice_kidney_5 = compute_surface_dice_score(kidney_5_submit_df, kidney_5_label_df)\n","print(f'Surface dice for public test (kidney_5) set is: {surface_dice_kidney_5}')\n","\n","surface_dice_kidney_6 = compute_surface_dice_score(kidney_6_submit_df, kidney_6_label_df)\n","print(f'Surface dice for private test (kidney_6) set is: {surface_dice_kidney_6}')"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":6962461,"sourceId":61446,"sourceType":"competition"},{"datasetId":4310240,"sourceId":7410561,"sourceType":"datasetVersion"},{"datasetId":4318140,"sourceId":7421807,"sourceType":"datasetVersion"},{"datasetId":4319795,"sourceId":7424375,"sourceType":"datasetVersion"},{"datasetId":4323420,"sourceId":7429516,"sourceType":"datasetVersion"},{"datasetId":4326041,"sourceId":7433689,"sourceType":"datasetVersion"},{"datasetId":4331972,"sourceId":7472030,"sourceType":"datasetVersion"},{"datasetId":4337906,"sourceId":7518542,"sourceType":"datasetVersion"},{"datasetId":4381896,"sourceId":7536908,"sourceType":"datasetVersion"},{"datasetId":4389271,"sourceId":7540532,"sourceType":"datasetVersion"},{"datasetId":4391156,"sourceId":7540826,"sourceType":"datasetVersion"},{"datasetId":4399111,"sourceId":7553758,"sourceType":"datasetVersion"},{"datasetId":4401981,"sourceId":7571887,"sourceType":"datasetVersion"},{"sourceId":150248402,"sourceType":"kernelVersion"}],"dockerImageVersionId":30636,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
